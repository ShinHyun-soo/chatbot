{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48e56fe1",
   "metadata": {},
   "source": [
    "© 2023 summer https://fastcampus.co.kr/data_online_llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b06c5f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04e30f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(50257, 512, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=512, out_features=1376, bias=False)\n",
       "          (up_proj): Linear(in_features=512, out_features=1376, bias=False)\n",
       "          (down_proj): Linear(in_features=1376, out_features=512, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import LlamaForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('news_gpt2')\n",
    "model = LlamaForCausalLM.from_pretrained('news_llama')\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f122b418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If there were an annual prize for the \"World\\'s Most Hopeful Economy,\" it would likely go the way of the \"World\\'s Most Wanted\" -- a list of the world\\'s top 10 most wanted fugitives. The list of the top 10 most wanted fugitives is a list of the most wanted fugitives, with the most wanted fugitives, according to the list of the most wanted fugitives. The list includes the most wanted fugitives, with the most wanted fugitives, with the most wanted fugitives, according to the list'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "prompt = \"\"\"\\\n",
    "If there were an annual prize for the \"World\\'s Most Hopeful Economy,\" it would likely go the\"\"\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "inputs.to(device)\n",
    "\n",
    "# Generate\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=100)\n",
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42143cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria, but the president has said he will not use force against ISIS. The president's comments came as the U.S. military\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in\"\"\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "inputs.to(device)\n",
    "\n",
    "# Generate\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=50)\n",
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdec1ac7",
   "metadata": {},
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f0a7c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'title', 'text', 'label'],\n",
       "        num_rows: 24353\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Unnamed: 0', 'title', 'text', 'label'],\n",
       "        num_rows: 8117\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'title', 'text', 'label'],\n",
       "        num_rows: 8117\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "data = 'GonzaloA/fake_news'\n",
    "dataset = load_dataset(data)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9931dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': 0,\n",
       " 'title': ' ‘Maury’ Show Official Facebook Posts F*CKED UP Caption On Guest That Looks Like Ted Cruz (IMAGE)',\n",
       " 'text': 'Maury is perhaps one of the trashiest shows on television today. It s right in line with the likes of the gutter trash that is Jerry Springer, and the fact that those shows are still on the air with the shit they air really is a sad testament to what Americans find to be entertaining. However, Maury really crossed the line with a Facebook post regarding one of their guest s appearance with a vile, disgusting caption on Tuesday evening.There was a young woman on there doing one of their episodes regarding the paternity of her child. However, on the page, the show posted an image of the woman, who happens to bear a striking resemblance to Senator and presidential candidate Ted Cruz. The caption from the Maury Show page read: The Lie Detector Test determined .that was a LIE!  Ted Cruz is just NOT that SEXY! As if that weren t horrible enough, the caption underneath the Imgur upload reads,  Ted Cruz in drag on Maury. Here is an image from the official Maury Facebook page:Here is the embed of the post itself:This is beyond despicable. It s bad enough that this show preys on desperate people to keep their trashy show going and their audience of bottom-feeders entertained, but now they publicly mock them as well? This young woman cannot help how she looks or who she resembles. That is not her fault. Shaming someone s looks on social media is something we d expect from the morons who watch this crap on a daily basis, but it is NOT something the official show page should be doing. Then again, what can you expect from a show that rolls in the mud for a living and continues to show the world that there is now low they will not stoop to? This was more than a step too far, though.Maury, you owe this young woman a public apology. A VERY public apology. There s just no excuse for this, no matter the demographics of your audience or what you do on that disgusting show of yours. I suppose it will be too much to ask that you lose viewers over this, because the people who watch your trashy ass show likely aren t educated enough to understand why this is so wrong in the first place. I don t watch, so I can t deprive you of my viewership, but I CAN call you out.Shame on you, Maury Show and everyone associated with this despicable Facebook post. You really showed your true colors here today.Featured image via Facebook ',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d6df0e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': Value(dtype='int64', id=None),\n",
       " 'title': Value(dtype='string', id=None),\n",
       " 'text': Value(dtype='string', id=None),\n",
       " 'label': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "667b7dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "int2label = {0: 'False', 1: 'True'}\n",
    "label2int = {'False': 0, 'True': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76d8ef08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Determine if the given article is fake. article: ‘Maury’ Show Official Facebook Posts F*CKED UP Caption On Guest That Looks Like Ted Cruz (IMAGE) answer: “I’m not a racist, I’m not a racist, I’m'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"\\\n",
    "Determine if the given article is fake. article: ‘Maury’ Show Official Facebook Posts F*CKED UP Caption On Guest That Looks Like Ted Cruz (IMAGE) answer:\"\"\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "inputs.to(device)\n",
    "\n",
    "# Generate\n",
    "generate_ids = model.generate(inputs.input_ids, max_length = 60)\n",
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9ff5b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9735eec14ff3400b97e8d132c3d311ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24353 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90cf96955a246f0a01787b6c505d9d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd116762aad402db59643bdff52bcbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "import random\n",
    "\n",
    "prompt_format1 = \"\"\"Determine if the given article is fake. article: %s  answer: %s\"\"\"\n",
    "prompt_format2 = \"\"\"Is this article fake? article: %s answer: %s\"\"\"\n",
    "prompt_format3 = \"\"\"Return True if the given article is fake. article: %s answer: %s\"\"\"\n",
    "\n",
    "prompts = [prompt_format1, prompt_format2, prompt_format3]\n",
    "def gen_prompt_fake(element):\n",
    "    prompt_format = prompts[random.randint(0, len(prompts)-1)]\n",
    "    return DatasetDict({'input': prompt_format%(element['title'], int2label[element['label']])})\n",
    "\n",
    "\n",
    "dataset['train'] = dataset['train'].map(gen_prompt_fake)\n",
    "dataset['validation'] = dataset['validation'].map(gen_prompt_fake)\n",
    "dataset['test'] = dataset['test'].map(gen_prompt_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c51e03eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': 0,\n",
       " 'title': ' ‘Maury’ Show Official Facebook Posts F*CKED UP Caption On Guest That Looks Like Ted Cruz (IMAGE)',\n",
       " 'text': 'Maury is perhaps one of the trashiest shows on television today. It s right in line with the likes of the gutter trash that is Jerry Springer, and the fact that those shows are still on the air with the shit they air really is a sad testament to what Americans find to be entertaining. However, Maury really crossed the line with a Facebook post regarding one of their guest s appearance with a vile, disgusting caption on Tuesday evening.There was a young woman on there doing one of their episodes regarding the paternity of her child. However, on the page, the show posted an image of the woman, who happens to bear a striking resemblance to Senator and presidential candidate Ted Cruz. The caption from the Maury Show page read: The Lie Detector Test determined .that was a LIE!  Ted Cruz is just NOT that SEXY! As if that weren t horrible enough, the caption underneath the Imgur upload reads,  Ted Cruz in drag on Maury. Here is an image from the official Maury Facebook page:Here is the embed of the post itself:This is beyond despicable. It s bad enough that this show preys on desperate people to keep their trashy show going and their audience of bottom-feeders entertained, but now they publicly mock them as well? This young woman cannot help how she looks or who she resembles. That is not her fault. Shaming someone s looks on social media is something we d expect from the morons who watch this crap on a daily basis, but it is NOT something the official show page should be doing. Then again, what can you expect from a show that rolls in the mud for a living and continues to show the world that there is now low they will not stoop to? This was more than a step too far, though.Maury, you owe this young woman a public apology. A VERY public apology. There s just no excuse for this, no matter the demographics of your audience or what you do on that disgusting show of yours. I suppose it will be too much to ask that you lose viewers over this, because the people who watch your trashy ass show likely aren t educated enough to understand why this is so wrong in the first place. I don t watch, so I can t deprive you of my viewership, but I CAN call you out.Shame on you, Maury Show and everyone associated with this despicable Facebook post. You really showed your true colors here today.Featured image via Facebook ',\n",
       " 'label': 0,\n",
       " 'input': 'Return True if the given article is fake. article:  ‘Maury’ Show Official Facebook Posts F*CKED UP Caption On Guest That Looks Like Ted Cruz (IMAGE) answer: False'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b80620d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>‘Maury’ Show Official Facebook Posts F*CKED U...</td>\n",
       "      <td>Maury is perhaps one of the trashiest shows on...</td>\n",
       "      <td>0</td>\n",
       "      <td>Return True if the given article is fake. arti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Trump’s Favorite News Channel Tries To Soothe...</td>\n",
       "      <td>Yesterday, after the father of one of the UCLA...</td>\n",
       "      <td>0</td>\n",
       "      <td>Return True if the given article is fake. arti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Russia warns Iraq, Kurds not to destabilize Mi...</td>\n",
       "      <td>MOSCOW (Reuters) - Russia on Wednesday warned ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Return True if the given article is fake. arti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>WATCH STEVE SCALISE Throw A Strike At The Nati...</td>\n",
       "      <td>House Majority Whip Steve Scalise (R., La.) th...</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine if the given article is fake. articl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Trump Will HATE What Stephen Colbert Just Did...</td>\n",
       "      <td>It can be said that Late Show host Stephen Col...</td>\n",
       "      <td>0</td>\n",
       "      <td>Is this article fake? article:  Trump Will HAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24348</th>\n",
       "      <td>24348</td>\n",
       "      <td>EU Parliament chief asks Poland to ensure MEPs...</td>\n",
       "      <td>WARSAW (Reuters) - The president of the Europe...</td>\n",
       "      <td>1</td>\n",
       "      <td>Is this article fake? article: EU Parliament c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24349</th>\n",
       "      <td>24349</td>\n",
       "      <td>Chemical weapons watchdog found sarin used in ...</td>\n",
       "      <td>AMSTERDAM/UNITED NATIONS (Reuters) - An inquir...</td>\n",
       "      <td>1</td>\n",
       "      <td>Is this article fake? article: Chemical weapon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24350</th>\n",
       "      <td>24350</td>\n",
       "      <td>Melissa Harris-Perry Is DONE With MSNBC, Pens...</td>\n",
       "      <td>As you may or may not know at this point, MSNB...</td>\n",
       "      <td>0</td>\n",
       "      <td>Is this article fake? article:  Melissa Harris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24351</th>\n",
       "      <td>24351</td>\n",
       "      <td>Trump's pick for Navy secretary withdraws</td>\n",
       "      <td>WASHINGTON (Reuters) - U.S. President Donald T...</td>\n",
       "      <td>1</td>\n",
       "      <td>Determine if the given article is fake. articl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24352</th>\n",
       "      <td>24352</td>\n",
       "      <td>Ukraine's Tymoshenko expects fair U.S. ruling ...</td>\n",
       "      <td>KIEV (Reuters) - Ukrainian opposition leader Y...</td>\n",
       "      <td>1</td>\n",
       "      <td>Return True if the given article is fake. arti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24353 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                              title  \\\n",
       "0               0   ‘Maury’ Show Official Facebook Posts F*CKED U...   \n",
       "1               1   Trump’s Favorite News Channel Tries To Soothe...   \n",
       "2               2  Russia warns Iraq, Kurds not to destabilize Mi...   \n",
       "3               3  WATCH STEVE SCALISE Throw A Strike At The Nati...   \n",
       "4               4   Trump Will HATE What Stephen Colbert Just Did...   \n",
       "...           ...                                                ...   \n",
       "24348       24348  EU Parliament chief asks Poland to ensure MEPs...   \n",
       "24349       24349  Chemical weapons watchdog found sarin used in ...   \n",
       "24350       24350   Melissa Harris-Perry Is DONE With MSNBC, Pens...   \n",
       "24351       24351          Trump's pick for Navy secretary withdraws   \n",
       "24352       24352  Ukraine's Tymoshenko expects fair U.S. ruling ...   \n",
       "\n",
       "                                                    text  label  \\\n",
       "0      Maury is perhaps one of the trashiest shows on...      0   \n",
       "1      Yesterday, after the father of one of the UCLA...      0   \n",
       "2      MOSCOW (Reuters) - Russia on Wednesday warned ...      1   \n",
       "3      House Majority Whip Steve Scalise (R., La.) th...      0   \n",
       "4      It can be said that Late Show host Stephen Col...      0   \n",
       "...                                                  ...    ...   \n",
       "24348  WARSAW (Reuters) - The president of the Europe...      1   \n",
       "24349  AMSTERDAM/UNITED NATIONS (Reuters) - An inquir...      1   \n",
       "24350  As you may or may not know at this point, MSNB...      0   \n",
       "24351  WASHINGTON (Reuters) - U.S. President Donald T...      1   \n",
       "24352  KIEV (Reuters) - Ukrainian opposition leader Y...      1   \n",
       "\n",
       "                                                   input  \n",
       "0      Return True if the given article is fake. arti...  \n",
       "1      Return True if the given article is fake. arti...  \n",
       "2      Return True if the given article is fake. arti...  \n",
       "3      Determine if the given article is fake. articl...  \n",
       "4      Is this article fake? article:  Trump Will HAT...  \n",
       "...                                                  ...  \n",
       "24348  Is this article fake? article: EU Parliament c...  \n",
       "24349  Is this article fake? article: Chemical weapon...  \n",
       "24350  Is this article fake? article:  Melissa Harris...  \n",
       "24351  Determine if the given article is fake. articl...  \n",
       "24352  Return True if the given article is fake. arti...  \n",
       "\n",
       "[24353 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "507ca779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7837c84eda3b4bb7bcd80e8939008aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24353 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e584dead6cc45228c2b3a3286f05262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb9f50922faf4ccc88a261e9c2455f15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids'],\n",
       "        num_rows: 24353\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids'],\n",
       "        num_rows: 8117\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids'],\n",
       "        num_rows: 8117\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(element):\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    outputs = tokenizer(\n",
    "        element['input'],\n",
    "        truncation=True,\n",
    "        max_length=context_length,\n",
    "        return_overflowing_tokens=False,\n",
    "        return_length=True,\n",
    "        padding=True\n",
    "    )\n",
    "    input_batch = []\n",
    "    for inputs, input_ids, labels in zip(element[\"input\"], outputs[\"input_ids\"], element['label']):\n",
    "        input_batch.append(input_ids)\n",
    "    return {\"input_ids\": input_batch}\n",
    "\n",
    "\n",
    "context_length=128\n",
    "tokenized_datasets = dataset.map(\n",
    "    tokenize, batched=True, remove_columns=dataset['train'].column_names\n",
    ")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae5fe66",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "360103f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d90fc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([5, 91])\n",
      "attention_mask shape: torch.Size([5, 91])\n",
      "labels shape: torch.Size([5, 91])\n"
     ]
    }
   ],
   "source": [
    "out = data_collator([tokenized_datasets['train'][i] for i in range(5)])\n",
    "for key in out:\n",
    "    print(f\"{key} shape: {out[key].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5e266da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"fake_detect_llama\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=1_00,\n",
    "    logging_steps=1_00,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.1,\n",
    "    warmup_steps=1_00,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    learning_rate=5e-4,\n",
    "    save_steps=1_00,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d3a68c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='601' max='761' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [601/761 05:06 < 01:21, 1.96 it/s, Epoch 0.79/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.348000</td>\n",
       "      <td>3.704400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.596700</td>\n",
       "      <td>3.689918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.713500</td>\n",
       "      <td>3.649371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.713700</td>\n",
       "      <td>3.618085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.672200</td>\n",
       "      <td>3.608093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='2030' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   1/2030 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20004\\1245619154.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1553\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1554\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1555\u001b[1;33m             return inner_training_loop(\n\u001b[0m\u001b[0;32m   1556\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1557\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1927\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1929\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1930\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1931\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_substep_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[1;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2254\u001b[0m                     \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_metrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2255\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2256\u001b[1;33m                 \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2257\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   2970\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2971\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2972\u001b[1;33m         output = eval_loop(\n\u001b[0m\u001b[0;32m   2973\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2974\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Evaluation\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   3191\u001b[0m                 \u001b[0mlabels_host\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlabels_host\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnested_concat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_host\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3193\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_prediction_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3195\u001b[0m             \u001b[1;31m# Gather all tensors and put them back on the CPU if we have done enough accumulation steps.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer_callback.py\u001b[0m in \u001b[0;36mon_prediction_step\u001b[1;34m(self, args, state, control)\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_prediction_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTrainerState\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTrainerControl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"on_prediction_step\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer_callback.py\u001b[0m in \u001b[0;36mcall_event\u001b[1;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m             result = getattr(callback, event)(\n\u001b[0m\u001b[0;32m    407\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\utils\\notebook.py\u001b[0m in \u001b[0;36mon_prediction_step\u001b[1;34m(self, args, state, control, eval_dataloader, **kwargs)\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction_bar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction_bar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction_bar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\utils\\notebook.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, value, force_update, comment)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage_time_per_item\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredicted_remaining\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage_time_per_item\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_bar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\utils\\notebook.py\u001b[0m in \u001b[0;36mupdate_bar\u001b[1;34m(self, value, comment)\u001b[0m\n\u001b[0;32m    178\u001b[0m                 \u001b[1;34mf\" {format_time(self.predicted_remaining)}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m             )\n\u001b[1;32m--> 180\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34mf\", {1/self.average_time_per_item:.2f} it/s\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"]\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomment\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomment\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34mf\", {self.comment}]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "trainer.train() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719d9203",
   "metadata": {},
   "source": [
    "# evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4880547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Determine if the given article is fake. article: Boeing CEO says he assured Trump about Air Force One costs  answer: True'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][234]['input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89ba8a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return True if the given article is fake. article: Boeing CEO says he assured Trump about Air Force One costs answer: True if the given article is fake. answer: True if the given article is fake. answer: True if the given article\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Return True if the given article is fake. article: Boeing CEO says he assured Trump about Air Force One costs answer:\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "inputs.to(device)\n",
    "\n",
    "# Generate\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=50)\n",
    "output = tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1beb6644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a53495e4b54cedb3254e09d081fc3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': 0,\n",
       " 'title': 'FORMER U.S. ATTORNEY: “It’s VERY Clear Intel Conspired to Frame Trump” (VIDEO)',\n",
       " 'text': 'JOE DIGENOVA has been around D.C for decades and has seen it all. He probably didn t see his one coming. The incoming president  was set-up to be taken down. A soft coup is in the works and DiGenova has this to say about it:\"It\\'s very clear that they conspired to frame the incoming President of the United States.\"  Joe diGenova on allegations of anti-Trump bias at FBI and TheJusticeDept #Tucker https://t.co/qUNjAenzJc pic.twitter.com/VDlhb45Ghi  G. Ashley Hawkins (@g_ashleyhawkins) December 16, 2017DiGenova on Tucker Carlson tonight: Inside the FBI and Department of Justice under Obama was a brazen plot to do two things. To exonerate Hillary Clinton because of an animous for Donald Trump, and then if she lost to frame the incoming president for either a criminal act or impeachment. This is one of the most disgusting performances by the senior officials at the FBI and the Department of Justice that everyone of these agents should be fired and the people who are still in the Justice Department be fired including Mr. Ohr and they impanel a federal grand jury to investigate the conduct of McCabe and Strzok and Page and Comey and Ohr and everybody in the Obama Justice Department that even touched this. It s very clear that they conspired to frame the incoming president of the United States.DIGENOVA S WIFE VICTORIA TOENSING IS REPRESENTING A FORMER FBI INFORMANT WHO HAS THE GOODS ON THE URANIUM ONE DEAL: DC lawyer Victoria Toensing is one smart cookie. She s representing a former FBI informant who has evidence on kickbacks and bribery involving the transportation of uranium in the US. She recently told Sean Hannity her client will brief Congress about Russian involvement in the U.S. uranium market. This includes widespread bribery and actions that involved the Clintons https://www.youtube.com/watch?v=eDVndQRW22Q I m not going into detail,  attorney Victoria Toensing said on the Oct. 24 Hannity.  You know that, Sean. But the informant will give an overview and specific conversations that he had with Russians in what they were thinking about the money that they were spending. I mean, let me just be that general and it involves the Clintons. The director of the FBI at that time was Robert Mueller, and he is now the special counsel investigating alleged Russian collusion with the 2016 Trump campaign. The undercover investigation involving Toensing s client occurred between 2009 and 2014, and the senior attorney on the case was Rod Rosenstein, who is now the deputy attorney general of the United States and the official who appointed Mueller as special counsel.Further, all this information indicates that many senior Obama administration officials knew about instances of bribery and money laundering involving at least one Russian official, at a time when Russia wanted to expand its uranium market in the United States, and when the administration through a special committee had to approve or deny the sale of a company, Vancouver-based Uranium One, to Rosatom. (Rosatom is the Russian State Atomic Energy Corporation.)Some of the people on that Committee on Foreign Investment in the United States included then-Secretary of State Hillary Clinton, Attorney General Eric Holder, Homeland Security Secretary Janet Napalitano, and Treasury Secretary Timothy Geithner.The committee approved the sale of Uranium One to Rosatom in October 2010. That sale gave Russia, and President Vladimir Putin, control over 20% of U.S. uranium production. (At least nine investors in Uranium One   prior to, during, and after that sale   donated $145 million to the Clinton Foundation.) So, Mueller, [Rod] Rosenstein, maybe even [James] Comey at the time, and the president of the United States   certainly Eric Holder was the head of the DOJ   they all knew that they had all this evidence that the Russians had infiltrated with the purpose of a criminal enterprise to corner the market on uranium, the foundational material of nuclear weapons?  asked Hannity.Toensing said,  That is correct. Via: cns news',\n",
       " 'label': 0,\n",
       " 'input': 'Return True if the given article is fake. article: FORMER U.S. ATTORNEY: “It’s VERY Clear Intel Conspired to Frame Trump” (VIDEO) answer:'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"news_gpt2\", padding_side='left')\n",
    "\n",
    "\n",
    "prompt_format1 = \"\"\"Determine if the given article is fake. article: %s  answer:\"\"\"\n",
    "prompt_format2 = \"\"\"Is this article fake? article: %s answer:\"\"\"\n",
    "prompt_format3 = \"\"\"Return True if the given article is fake. article: %s answer:\"\"\"\n",
    "\n",
    "prompts = [prompt_format1, prompt_format2, prompt_format3]\n",
    "\n",
    "def gen_valid_prompt(element):\n",
    "    prompt_format = prompts[random.randint(0, len(prompts)-1)]\n",
    "    return DatasetDict({'input': prompt_format%(element['title'])})\n",
    "\n",
    "\n",
    "valid_dataset = dataset['test'].select(range(100)).map(gen_valid_prompt)\n",
    "valid_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "361b6016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b688438f8b4919aaec250ee5478e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'input_ids'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset = valid_dataset.map(\n",
    "    tokenize, batched=True, remove_columns=['text', 'input', 'Unnamed: 0', 'title']\n",
    ")\n",
    "valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d51b49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size=4\n",
    "val_ds = valid_dataset\n",
    "val_ds.set_format(type='torch')\n",
    "val_dl = DataLoader(val_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c70510de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def acc(pred,label):\n",
    "    return torch.sum(torch.tensor(pred) == label.squeeze()).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b10a3304",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:09<00:00,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val acc:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_orig = LlamaForCausalLM.from_pretrained('news_llama')\n",
    "model_orig.to(device)\n",
    "model_orig.eval()\n",
    "\n",
    "val_losses = []\n",
    "val_acc = 0\n",
    "\n",
    "for step, batch in enumerate(tqdm(val_dl)):\n",
    "    label = batch['label']\n",
    "    input_id= batch['input_ids'].to(device)\n",
    "\n",
    "    pred = model_orig.generate(input_id, max_length=128)\n",
    "    decoded_pred = tokenizer.batch_decode(pred, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "    decoded_pred = [re.findall(\"answer: (True|False)\", x)[0] if re.findall(\"answer: (True|False)\", x) else 'none' for x in decoded_pred]\n",
    "    decoded_pred = [label2int[x] if x in label2int else -1 for x in decoded_pred]\n",
    "\n",
    "    val_acc += acc(decoded_pred, label)\n",
    "    \n",
    "\n",
    "print(\"val acc: \", val_acc/len(val_dl.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46d17462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([\"Determine if the given article is fake. article: WATCH DIRTY HARRY REID ON HIS LIE ABOUT ROMNEY’S TAXES: “HE DIDN’T WIN, DID HE?”  answer: 'HE DIDN'TY HARRY, NO ONE OF THEMENT LIFE'S HEART: 'HE DIDN'TY HARRY, NO ONE OF THEMENT LIFE'S HEART: 'HE DIDN\",\n",
       "  \"Is this article fake? article: North Korea diplomat says take atmospheric nuclear test threat 'literally' answer: 'I'm not sure if it's true.' The U.S. official said the U.S. is 'very concerned' about the North's nuclear program, but that the U.S. is 'very concerned' about the North's nuclear program. 'We are concerned about the North\",\n",
       "  \"Is this article fake? article: VIRAL VIDEO: German Youth Deliver Powerful Anti-Refugee Message To Political Leaders: “We are ready for the Reconquista!” answer: 'We are ready to go to the World Cup. We are ready to go to the World Cup. We are ready to go to the World Cup. We are ready to go to the World Cup. We are ready to go to the World Cup. We are ready to go to the World Cup\",\n",
       "  'Is this article fake? article: Polish ruling party replaces PM ahead of elections answer: . \"I am not a racist, but I am a racist. I am a racist. I am a racist. I am a racist. I am a racist. I am a racist. I am a racist. I am a racist. I am a racist. I am a racist. I'],\n",
       " tensor([0, 1, 0, 1]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(pred, skip_special_tokens=True, clean_up_tokenization_spaces=False), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ddb9cdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/25 [00:00<?, ?it/s]This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (128). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:17<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val acc:  0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "val_losses = []\n",
    "val_acc = 0\n",
    "\n",
    "for step, batch in enumerate(tqdm(val_dl)):\n",
    "    label = batch['label']\n",
    "    input_id= batch['input_ids'].to(device)\n",
    "\n",
    "    pred = model.generate(input_id, max_length=150)\n",
    "    decoded_pred = tokenizer.batch_decode(pred, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "    decoded_pred = [re.findall(\"answer: ([^ ]*)\", x)[0] if re.findall(\"answer: ([^ ]*)\", x) else 'none' for x in decoded_pred]\n",
    "    decoded_pred = [label2int[x] if x in label2int else -1 for x in decoded_pred]\n",
    "\n",
    "    val_acc += acc(decoded_pred, label)\n",
    "    \n",
    "\n",
    "print(\"val acc: \", val_acc/len(val_dl.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec8a73f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Determine if the given article is fake. article: WATCH DIRTY HARRY REID ON HIS LIE ABOUT ROMNEY’S TAXES: “HE DIDN’T WIN, DID HE?”  answer: False News For Trump’s “A “A*B*B*B*B*B*B*B*B*B*B*B*B*B*B*B*B*B*B*B*B*B*B*B*B*B*B*B*B*B*B*B*B*B*B*B*B',\n",
       "  \"Is this article fake? article: North Korea diplomat says take atmospheric nuclear test threat 'literally' answer: True if the given article is fake. answer: True if the given article is fake. answer: True if the given article is fake. answer: True if the given article is fake. article: Trump says U.S. sanctions on North Korea are 'unjust a threat' answer: True if the given article is fake. answer: True if the given article is fake. China's Xi says U\",\n",
       "  'Is this article fake? article: VIRAL VIDEO: German Youth Deliver Powerful Anti-Refugee Message To Political Leaders: “We are ready for the Reconquista!” answer: Falsely Stupidly uneased “Refugees” [Video] answer: Falsely Stupid Reason She’s A “A*cking” [Video] answer: Falsely Falsely Stupid Reason She’s A “A*cking” [Video] answer: Falsely Falsely Stupid Reason She’s A “A*cking” [V',\n",
       "  \"Is this article fake? article: Polish ruling party replaces PM ahead of elections answer: True answer: True if the given article is fake. answer: True if the given article is fake. answer: True if the given article is fake. answer: True if the given article is fake. EU's Tusk says EU membership in EU membership answer: True if the given article is fake. EU membership: True if the given article is fake. EU membership: EU's Tusk answer: True if the\"],\n",
       " tensor([0, 1, 0, 1]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(pred, skip_special_tokens=True, clean_up_tokenization_spaces=False), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6b43337",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('fake_detect_llama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc9397e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8216019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd405462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414f3468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b692964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9980639e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1506032e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
